% From Recompilation 20250504

@misc{vendrow2025largelanguagemodelbenchmarks,
      title={Do Large Language Model Benchmarks Test Reliability?}, 
      author={Joshua Vendrow and Edward Vendrow and Sara Beery and Aleksander Madry},
      year={2025},
      eprint={2502.03461},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.03461}, 
}

@misc{jimenez2024swebenchlanguagemodelsresolve,
      title={SWE-bench: Can Language Models Resolve Real-World GitHub Issues?},
      author={Carlos E. Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik Narasimhan},
      year={2024},
      eprint={2310.06770},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06770},
}

@misc{chen2021evaluatinglargelanguagemodels,
      title={Evaluating Large Language Models Trained on Code},
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2107.03374},
}

@misc{yu2024humanevalprombpppro,
      title={HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation},
      author={Zhaojian Yu and Yilun Zhao and Arman Cohan and Xiao-Ping Zhang},
      year={2024},
      eprint={2412.21199},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2412.21199},
}

@article{austin2021program,
    title={Program Synthesis with Large Language Models},
    author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
    journal={arXiv preprint arXiv:2108.07732},
    year={2021}
}

@misc{yang2023intercodestandardizingbenchmarkinginteractive,
      title={InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback},
      author={John Yang and Akshara Prabhakar and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2306.14898},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.14898},
}

@misc{chen2025needhelpdesigningproactive,
      title={Need Help? Designing Proactive AI Assistants for Programming},
      author={Valerie Chen and Alan Zhu and Sebastian Zhao and Hussein Mozannar and David Sontag and Ameet Talwalkar},
      year={2025},
      eprint={2410.04596},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2410.04596},
}

@misc{mozannar2024readinglinesmodelinguser,
      title={Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming},
      author={Hussein Mozannar and Gagan Bansal and Adam Fourney and Eric Horvitz},
      year={2024},
      eprint={2210.14306},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2210.14306},
}

% TO DO not used
@misc{li2024promptinglargelanguagemodels,
      title={Prompting Large Language Models to Tackle the Full Software Development Lifecycle: A Case Study},
      author={Bowen Li and Wenhan Wu and Ziwei Tang and Lin Shi and John Yang and Jinyang Li and Shunyu Yao and Chen Qian and Binyuan Hui and Qicheng Zhang and Zhiyin Yu and He Du and Ping Yang and Dahua Lin and Chao Peng and Kai Chen},
      year={2024},
      eprint={2403.08604},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.08604},
}

% TO DO not used
@inproceedings{Zhang_2023, series={SEKE2023},
   title={Practices and Challenges of Using GitHub Copilot: An Empirical Study},
   volume={2023},
   ISSN={2325-9000},
   url={http://dx.doi.org/10.18293/SEKE2023-077},
   DOI={10.18293/seke2023-077},
   booktitle={Proceedings of the 35th International Conference on Software Engineering and Knowledge Engineering},
   publisher={KSI Research Inc.},
   author={Zhang, Beiqi and Liang, Peng and Zhou, Xiyu and Ahmad, Aakash and Waseem, Muhammad},
   year={2023},
   month=jul, pages={124–129},
   collection={SEKE2023} }

@inproceedings{uniyal2024one,
  title={One-to-many testing for code generation from (just) natural language},
  author={Uniyal, Mansi and Singh, Mukul and Verbruggen, Gust and Gulwani, Sumit and Le, Vu},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={15397--15402},
  year={2024}
}

@misc{miah2024usercentricevaluationcode,
      title={User Centric Evaluation of Code Generation Tools},
      author={Tanha Miah and Hong Zhu},
      year={2024},
      eprint={2402.03130},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2402.03130},
}

@article{evtikhiev2023out,
    title={Out of the bleu: how should we assess quality of the code generation models?},
    author={Evtikhiev, Mikhail and Bogomolov, Egor and Sokolov, Yaroslav and Bryksin, Timofey},
    journal={Journal of Systems and Software},
    volume={203},
    pages={111741},
    year={2023},
    publisher={Elsevier}
}

@article{crupi2025effectiveness,
    title={On the Effectiveness of LLM-as-a-judge for Code Generation and Summarization},
    author={Crupi, Giuseppe and Tufano, Rosalia and Velasco, Alejandro and Mastropaolo, Antonio and Poshyvanyk, Denys and Bavota, Gabriele},
    journal={IEEE Transactions on Software Engineering},
    year={2025},
    publisher={IEEE}
}

% TO DO not used
@misc{kulal2019spocsearchbasedpseudocodecode,
      title={SPoC: Search-based Pseudocode to Code},
      author={Sumith Kulal and Panupong Pasupat and Kartik Chandra and Mina Lee and Oded Padon and Alex Aiken and Percy Liang},
      year={2019},
      eprint={1906.04908},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1906.04908},
}


% TO DO not used
@misc{mialon2023gaiabenchmarkgeneralai,
      title={GAIA: a benchmark for General AI Assistants},
      author={Grégoire Mialon and Clémentine Fourrier and Craig Swift and Thomas Wolf and Yann LeCun and Thomas Scialom},
      year={2023},
      eprint={2311.12983},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.12983},
}

% TO DO not used
@misc{paul2024benchmarksmetricsevaluationscode,
      title={Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review},
      author={Debalina Ghosh Paul and Hong Zhu and Ian Bayley},
      year={2024},
      eprint={2406.12655},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.12655},
}

% TO DO not used
@misc{chi2025copilotarenaplatformcode,
      title={Copilot Arena: A Platform for Code LLM Evaluation in the Wild},
      author={Wayne Chi and Valerie Chen and Anastasios Nikolas Angelopoulos and Wei-Lin Chiang and Aditya Mittal and Naman Jain and Tianjun Zhang and Ion Stoica and Chris Donahue and Ameet Talwalkar},
      year={2025},
      eprint={2502.09328},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2502.09328},
}

% TO DO not used


% Leaderboards

@misc{swebenchSWEbenchLeaderboards,
	author = {},
	title = {{S}{W}{E}-bench {L}eaderboards},
	howpublished = {\url{https://www.swebench.com/}},
	year = {},
	note = {[Accessed 17-08-2025]},
}

@misc{vellumLeaderboard2025,
	author = {},
	title = {{L}{L}{M} {L}eaderboard 2025 --- vellum.ai},
	howpublished = {\url{https://www.vellum.ai/llm-leaderboard}},
	year = {},
	note = {[Accessed 17-08-2025]},
}

@misc{huggingfaceOpenLeaderboard,
	author = {},
	title = {{O}pen {L}{L}{M} {L}eaderboard - a {H}ugging {F}ace {S}pace by open-llm-leaderboard --- huggingface.co},
	howpublished = {\url{https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard}},
	year = {},
	note = {[Accessed 17-08-2025]},
}

@misc{huggingfaceCalculation,
	author = {},
	title = {{L}{L}{M} {C}{O}2 emissions calculation - a {H}ugging {F}ace {S}pace --- huggingface.co},
	howpublished = {\url{https://huggingface.co/docs/leaderboards/open_llm_leaderboard/emissions}},
	year = {},
	note = {[Accessed 17-08-2025]},
}

@article{hendrycksapps2021,
    title={Measuring Coding Challenge Competence With APPS},
    author={Dan Hendrycks and Steven Basart and Saurav Kadavath and Mantas Mazeika and Akul Arora and Ethan Guo and Collin Burns and Samir Puranik and Horace He and Dawn Song and Jacob Steinhardt},
    journal={NeurIPS},
    year={2021}
}

@misc{mistralModelsBenchmarks,
    author = {},
    title = {{M}odels {B}enchmarks | {M}istral {A}{I}},
    howpublished = {\url{https://docs.mistral.ai/getting-started/models/benchmark/}},
    year = {},
    note = {[Accessed 27-08-2025]},
}

@article{recode_wang2022,
    title = {ReCode: Robustness Evaluation of Code Generation Models},
    author = {Wang, Shiqi and
   Zheng, Li and
   Qian, Haifeng and
   Yang, Chenghao and
   Wang, Zijian and
   Kumar, Varun and
   Shang, Mingyue and
   Tan, Samson and
   Ray, Baishakhi and
   Bhatia, Parminder and
   Nallapati, Ramesh and
   Ramanathan, Murali Krishna and
   Roth, Dan and
   Xiang, Bing},
    doi = {10.48550/arXiv.2212.10264},
    url = {https://arxiv.org/abs/2212.10264},
    keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL)},
    publisher = {arXiv},
    year = {2022},
    copyright = {Creative Commons Attribution 4.0 International}
}

% GITHUB

@misc{githubGitHubEleutherAIlmevaluationharness,
  author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
  title        = {The Language Model Evaluation Harness},
  month        = 07,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {v0.4.3},
  doi          = {10.5281/zenodo.12608602},
  url          = {https://zenodo.org/records/12608602}
}

@misc{bigcode-evaluation-harness,
  author       = {Ben Allal, Loubna and
                  Muennighoff, Niklas and
                  Kumar Umapathi, Logesh and
                  Lipkin, Ben and
                  von Werra, Leandro},
  title = {A framework for the evaluation of code generation models},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/bigcode-project/bigcode-evaluation-harness}},
  year = 2022,
}